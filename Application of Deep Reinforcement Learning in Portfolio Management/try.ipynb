{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mpl_dates\n",
    "\n",
    "import random\n",
    "from collections import deque, namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "#from tensorboardX import SummaryWriter\n",
    "import gymnasium as gym\n",
    "\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingGraph:\n",
    "    # A crypto trading visualization using matplotlib made to render custom prices which come in following way:\n",
    "    # Date, Open, High, Low, Close, Volume, net_worth, trades\n",
    "    # call render every step\n",
    "    def __init__(self, render_range):\n",
    "        self.volume = deque(maxlen=render_range)\n",
    "        self.net_worth = deque(maxlen=render_range)\n",
    "        self.render_data = deque(maxlen=render_range)\n",
    "        self.render_range = render_range\n",
    "\n",
    "        # We are using the style ‘ggplot’\n",
    "        plt.style.use('ggplot')\n",
    "        # close all plots if there are open\n",
    "        plt.close('all')\n",
    "        # figsize attribute allows us to specify the width and height of a figure in unit inches\n",
    "        self.fig = plt.figure(figsize=(16,8)) \n",
    "\n",
    "        # Create top subplot for price axis\n",
    "        self.ax1 = plt.subplot2grid((6,1), (0,0), rowspan=5, colspan=1)\n",
    "        \n",
    "        # Create bottom subplot for volume which shares its x-axis\n",
    "        self.ax2 = plt.subplot2grid((6,1), (5,0), rowspan=1, colspan=1, sharex=self.ax1)\n",
    "        \n",
    "        # Create a new axis for net worth which shares its x-axis with price\n",
    "        self.ax3 = self.ax1.twinx()\n",
    "\n",
    "        # Formatting Date\n",
    "        self.date_format = mpl_dates.DateFormatter('%d-%m-%Y')\n",
    "        \n",
    "        # Add paddings to make graph easier to view\n",
    "        #plt.subplots_adjust(left=0.07, bottom=-0.1, right=0.93, top=0.97, wspace=0, hspace=0)\n",
    "\n",
    "    # Render the environment to the screen\n",
    "    def render(self, date, open, high, low, close, volume, net_worth, trades):\n",
    "        # append volume and net_worth to deque list\n",
    "        self.volume.append(volume)\n",
    "        self.net_worth.append(net_worth)\n",
    "\n",
    "        # before appending to deque list, need to convert Date to special format\n",
    "        date = mpl_dates.date2num([pd.to_datetime(date)])[0]\n",
    "        self.render_data.append([date, open, high, low, close])\n",
    "        \n",
    "        # Clear the frame rendered last step\n",
    "        self.ax1.clear()\n",
    "        candlestick_ohlc(self.ax1, self.render_data, width=0.8/24, colorup='red', colordown='blue', alpha=0.8)\n",
    "\n",
    "        # Put all dates to one list and fill ax2 sublot with volume\n",
    "        date_render_range = [i[0] for i in self.render_data]\n",
    "        self.ax2.clear()\n",
    "        self.ax2.fill_between(date_render_range, self.volume, 0)\n",
    "\n",
    "        # draw our net_worth graph on ax3 (shared with ax1) subplot\n",
    "        self.ax3.clear()\n",
    "        self.ax3.plot(date_render_range, self.net_worth, color=\"blue\")\n",
    "        \n",
    "        # beautify the x-labels (Our Date format)\n",
    "        self.ax1.xaxis.set_major_formatter(self.date_format)\n",
    "        self.fig.autofmt_xdate()\n",
    "\n",
    "        # sort sell and buy orders, put arrows in appropiate order positions\n",
    "        for trade in trades:\n",
    "            trade_date = mpl_dates.date2num([pd.to_datetime(trade['Date'])])[0]\n",
    "            if trade_date in date_render_range:\n",
    "                if trade['Type'] == 'buy':\n",
    "                    high_low = trade['Low']-10\n",
    "                    self.ax1.scatter(trade_date, high_low, c='red', label='red', s = 120, edgecolors='none', marker=\"^\")\n",
    "                else:\n",
    "                    high_low = trade['High']+10\n",
    "                    self.ax1.scatter(trade_date, high_low, c='blue', label='blue', s = 120, edgecolors='none', marker=\"v\")\n",
    "\n",
    "        # we need to set layers every step, because we are clearing subplots every step\n",
    "        self.ax2.set_xlabel('Date')\n",
    "        self.ax1.set_ylabel('Price')\n",
    "        self.ax3.yaxis.set_label_position('right')\n",
    "        self.ax3.set_ylabel('Balance') # 여기 수정\n",
    "\n",
    "        # I use tight_layout to replace plt.subplots_adjust\n",
    "        self.fig.tight_layout()\n",
    "\n",
    "        \"\"\"Display image with matplotlib - interrupting other tasks\"\"\"\n",
    "        # Show the graph without blocking the rest of the program\n",
    "        plt.show(block=False)\n",
    "        # Necessary to view frames before they are unrendered\n",
    "        plt.pause(0.001)\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "        self.Transition = namedtuple('Transition',\n",
    "                                ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(self.Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_size):\n",
    "        super(Actor, self).__init__()\n",
    "        self.n_actions = 1\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer1 = nn.Linear(500, 256)\n",
    "        self.layer2 = nn.Linear(256, 64)\n",
    "        self.layer3 = nn.Linear(64, self.n_actions) # continuos action space니까 1이 되어야 하지 않을까? # \n",
    "        # action size: 여기서는 비트코인 한 종류만 다루고 있으므로 마지막을 1로 처리\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "\n",
    "        return torch.tanh(x) # tanh 함수는 결과값을 -1에서 1 사이로 가두어 준다. 그러므로 continuous action space에 알맞다.\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_size):\n",
    "        super(Critic, self).__init__()\n",
    "        self.n_actions = 1\n",
    "        # Layer 1\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer1 = nn.Linear(500, 256)\n",
    "        self.batch_norm_1 = nn.BatchNorm1d(256)\n",
    "\n",
    "        # Layer 2\n",
    "        # In the second layer the actions will be inserted also \n",
    "        self.layer2 = nn.Linear(256 + self.n_actions, 64)\n",
    "        self.batch_norm_2 = nn.BatchNorm1d(64)\n",
    "\n",
    "        # Output layer (single value)\n",
    "        self.layer3 = nn.Linear(64, 1)\n",
    "\n",
    "\n",
    "    def forward(self, inputs, action):\n",
    "\n",
    "        # Layer 1\n",
    "        x = self.flatten(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.batch_norm_1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Layer 2\n",
    "        x = torch.cat((x, action), 1)  # Insert the actions\n",
    "        x = self.layer2(x)\n",
    "        x = self.batch_norm_2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return self.layer3(x) # Value라서 x 대신 V라고도 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnv:\n",
    "    # A custom Bitcoin trading environment\n",
    "    def __init__(self, df, initial_balance=1000, lookback_window_size=50, render_range = 100):\n",
    "        # Define action space and state size and other custom parameters\n",
    "        self.df = df.dropna().reset_index()\n",
    "        self.df_total_steps = len(self.df)-1\n",
    "        self.initial_balance = initial_balance\n",
    "        self.lookback_window_size = lookback_window_size\n",
    "        self.render_range = render_range # render range in visualization\n",
    "\n",
    "        self.BATCH_SIZE = 500\n",
    "        self.GAMMA = 0.99\n",
    "        self.EPS_START = 0.9\n",
    "        self.EPS_END = 0.05\n",
    "        self.EPS_DECAY = 1000\n",
    "        self.TAU = 0.005\n",
    "        self.LR = 1e-4\n",
    "\n",
    "        #self.OU = OU_noise(1)\n",
    "\n",
    "    \n",
    "        self.memory = ReplayMemory(1000)\n",
    "\n",
    "        # Action space from -1 to 1. -1\n",
    "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(1,)) \n",
    "\n",
    "        # Orders history contains the balance, net_worth, crypto_bought, crypto_sold, crypto_held values for the last lookback_window_size steps\n",
    "        self.orders_history = deque(maxlen=self.lookback_window_size)\n",
    "        \n",
    "        # Market history contains the OHCL values for the last lookback_window_size prices\n",
    "        self.market_history = deque(maxlen=self.lookback_window_size)\n",
    "\n",
    "        # State size contains Market+Orders history for the last lookback_window_size steps\n",
    "        self.state_size = (self.lookback_window_size, 10)\n",
    "\n",
    "        self.Actor = Actor(self.state_size).to(device)\n",
    "        self.Critic = Critic(self.state_size).to(device)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.Actor.parameters(), lr=self.LR)\n",
    "\n",
    "    # Create tensorboard writer\n",
    "#    def create_writer(self):\n",
    "#        self.replay_count = 0\n",
    "#        self.writer = SummaryWriter(comment=\"Crypto_trader\")\n",
    "\n",
    "    # Reset the state of the environment to an initial state\n",
    "    def reset(self, env_steps_size = 0):\n",
    "        self.visualization = TradingGraph(render_range=self.render_range) # init visualization\n",
    "        self.trades = deque(maxlen=self.render_range) # limited orders memory for visualization\n",
    "        \n",
    "        self.balance = self.initial_balance\n",
    "        self.net_worth = self.initial_balance\n",
    "        self.prev_net_worth = self.initial_balance\n",
    "        self.crypto_held = 0\n",
    "        self.crypto_sold = 0\n",
    "        self.crypto_bought = 0\n",
    "        if env_steps_size > 0: # used for training dataset\n",
    "            self.start_step = random.randint(self.lookback_window_size, self.df_total_steps - env_steps_size)\n",
    "            self.end_step = self.start_step + env_steps_size\n",
    "        else: # used for testing dataset\n",
    "            self.start_step = self.lookback_window_size\n",
    "            self.end_step = self.df_total_steps\n",
    "            \n",
    "        self.current_step = self.start_step\n",
    "\n",
    "        for i in reversed(range(self.lookback_window_size)):\n",
    "            current_step = self.current_step - i\n",
    "            self.orders_history.append([self.balance, self.net_worth, self.crypto_bought, self.crypto_sold, self.crypto_held])\n",
    "            self.market_history.append([self.df.loc[current_step, 'open'],\n",
    "                                        self.df.loc[current_step, 'high'],\n",
    "                                        self.df.loc[current_step, 'low'],\n",
    "                                        self.df.loc[current_step, 'close'],\n",
    "                                        self.df.loc[current_step, 'volume']\n",
    "                                        ])\n",
    "\n",
    "        state = np.concatenate((self.market_history, self.orders_history), axis=1)\n",
    "        return state\n",
    "\n",
    "    # Get the data points for the given current_step\n",
    "    def _next_observation(self):\n",
    "        self.market_history.append([self.df.loc[self.current_step, 'open'],\n",
    "                                    self.df.loc[self.current_step, 'high'],\n",
    "                                    self.df.loc[self.current_step, 'low'],\n",
    "                                    self.df.loc[self.current_step, 'close'],\n",
    "                                    self.df.loc[self.current_step, 'volume']\n",
    "                                    ])\n",
    "        obs = np.concatenate((self.market_history, self.orders_history), axis=1)\n",
    "\n",
    "        #obs = np.concatenate((np.array(self.market_history), np.array(self.orders_history.cpu())), axis=1)\n",
    "        #obs =torch.cat([self.market_history, self.orders_history], dim=0)\n",
    "\n",
    "        return obs\n",
    "\n",
    "    # Execute one time step within the environment\n",
    "    def step(self, action):\n",
    "        #action = action.cpu() # 새로 추가한 부분\n",
    "        self.crypto_bought = 0\n",
    "        self.crypto_sold = 0\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Set the current price to a random price between open and close\n",
    "        current_price = random.uniform(\n",
    "            self.df.loc[self.current_step, 'open'],\n",
    "            self.df.loc[self.current_step, 'close'])\n",
    "        date = self.df.loc[self.current_step, 'date_open'] # for visualization\n",
    "        high = self.df.loc[self.current_step, 'high'] # for visualization\n",
    "        low = self.df.loc[self.current_step, 'low'] # for visualization\n",
    "        \n",
    "        if action == 0: # Hold\n",
    "            pass\n",
    "        \n",
    "        elif action > 0 and self.balance > self.initial_balance/100: # 0이 아닌 이유: 가끔 오류가 날 때 있음\n",
    "            self.crypto_bought = self.balance * action / current_price # 현금 * action으로 정해진 비율만큼 이용해서 구매\n",
    "            self.balance -= self.crypto_bought * current_price\n",
    "            self.crypto_held += self.crypto_bought\n",
    "            self.trades.append({'Date' : date, 'High' : high, 'Low' : low, 'Total': self.crypto_bought, 'Type': \"buy\"})\n",
    "        \n",
    "        elif action < 0 and self.crypto_held * abs(action) > 0: \n",
    "            self.crypto_sold = self.crypto_held * abs(action) \n",
    "            self.balance += self.crypto_sold * abs(action) * current_price\n",
    "            self.crypto_held -= self.crypto_sold\n",
    "            self.trades.append({'Date' : date, 'High' : high, 'Low' : low, 'Total': self.crypto_sold, 'Type': \"sell\"})\n",
    "\n",
    "        self.prev_net_worth = self.net_worth\n",
    "        self.net_worth = self.balance + self.crypto_held * current_price\n",
    "\n",
    "        self.orders_history.append([self.balance, self.net_worth, self.crypto_bought, self.crypto_sold, self.crypto_held])\n",
    "        #Write_to_file(Date, self.orders_history[-1])\n",
    "\n",
    "        # Calculate reward\n",
    "        reward = (self.net_worth - self.prev_net_worth)\n",
    "\n",
    "        if self.net_worth <= self.initial_balance/2:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        #obs = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        \n",
    "        return obs, reward, done\n",
    "\n",
    "    # render environment\n",
    "    def render(self, visualize=False):\n",
    "        #print(f'Step: {self.current_step}, Net Worth: {self.net_worth}')\n",
    "        if visualize:\n",
    "            date = self.df.loc[self.current_step, 'date_open']\n",
    "            open = self.df.loc[self.current_step, 'open']\n",
    "            close = self.df.loc[self.current_step, 'close']\n",
    "            high = self.df.loc[self.current_step, 'high']\n",
    "            low = self.df.loc[self.current_step, 'low']\n",
    "            volume = self.df.loc[self.current_step, 'volume']\n",
    "\n",
    "            # Render the environment to the screen\n",
    "            self.visualization.render(date, open, high, low, close, volume, self.net_worth, self.trades)\n",
    "    \n",
    "    def act(self, state, testmode): # select_action에 대응\n",
    "        state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            action = self.Actor(state) \n",
    "        #sample = random.random()\n",
    "        #eps_threshold = self.EPS_END + (self.EPS_START - self.EPS_END) * np.exp(-1 * self.current_step / self.EPS_DECAY)\n",
    "\n",
    "        #state_with_noise = torch.tensor(state_with_noise, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        #action_with_noise = action + torch.rand(1, device=device) * 0.1\n",
    "        action = action.cpu()\n",
    "        action_with_noise = action + np.random.rand(1) * 0.1    \n",
    "        if action_with_noise > 1:\n",
    "            action_with_noise = 1\n",
    "        elif action_with_noise < -1:\n",
    "            action_with_noise = -1\n",
    "        \n",
    "        if testmode == False:\n",
    "            #return torch.tensor([[action_with_noise]], device=device, dtype=torch.long)\n",
    "            return action_with_noise\n",
    "        else:\n",
    "            #return torch.tensor([[action]], device=device, dtype=torch.long)\n",
    "            return action\n",
    "\n",
    "\n",
    "        #if sample > eps_threshold:\n",
    "        #    with torch.no_grad():\n",
    "        #        return self.Actor(state).max(1).indices.view(1,1)\n",
    "        #else:\n",
    "        #    return torch.tensor([[np.random.choice(self.action_space)]], device=device, dtype=torch.long)\n",
    "    \n",
    "\n",
    "    def save(self, name=\"ddpg\"):\n",
    "        torch.save(self.Critic.state_dict(), f'./ddpg/{name}_Actor.h5')\n",
    "        torch.save(self.Actor.state_dict(), f'./ddpg/{name}_Critic.h5')\n",
    "\n",
    "    def load(self, name=\"dqn\"):\n",
    "        self.Actor.load_state_dict(torch.load(f'./ddpg/{name}_Actor.h5', weights_only=True))\n",
    "        self.Critic.load_state_dict(torch.load(f'./ddpg/{name}_Critic.h5', weights_only=True))\n",
    "        \n",
    "    def optimize_model(self):\n",
    "        if len(self.memory) < self.BATCH_SIZE:\n",
    "            return\n",
    "        Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "        transitions = self.memory.sample(self.BATCH_SIZE)\n",
    "        # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "        # detailed explanation). This converts batch-array of Transitions\n",
    "        # to Transition of batch-arrays.\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "        # Compute a mask of non-final states and concatenate the batch elements\n",
    "        # (a final state would've been the one after which simulation ended)\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                            batch.next_state)), device=device, dtype=torch.bool)\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                    if s is not None])\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "        # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "        # columns of actions taken. These are the actions which would've been taken\n",
    "        # for each batch state according to policy_net\n",
    "        state_action_values = self.Actor(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # Compute V(s_{t+1}) for all next states.\n",
    "        # Expected values of actions for non_final_next_states are computed based\n",
    "        # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "        # This is merged based on the mask, such that we'll have either the expected\n",
    "        # state value or 0 in case the state was final.\n",
    "        next_state_values = torch.zeros(self.BATCH_SIZE, device=device)\n",
    "        with torch.no_grad():\n",
    "            next_state_values[non_final_mask] = self.Critic(non_final_next_states).max(1).values\n",
    "        # Compute the expected Q values\n",
    "        expected_state_action_values = (next_state_values * self.GAMMA) + reward_batch\n",
    "\n",
    "        # Compute Huber loss\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # In-place gradient clipping\n",
    "        torch.nn.utils.clip_grad_value_(self.Actor.parameters(), 100)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "\n",
    "def train_agent(env, visualize=False, testmode=False, train_episodes=1, training_batch_size=500):\n",
    "    #env.create_writer() # create TensorBoard writer\n",
    "    #total_average = deque(maxlen=100) # save recent 100 episodes net worth\n",
    "    #best_average = 0 # used to track best average net worth\n",
    "    memory = ReplayMemory(1000)\n",
    "    \n",
    "    for episode in range(train_episodes):\n",
    "        state = env.reset(env_steps_size = training_batch_size)\n",
    "        state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        \n",
    "        for t in range(training_batch_size):\n",
    "            env.render(visualize)\n",
    "            action = env.act(state, testmode=testmode)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            #action_onehot = np.zeros(3)\n",
    "            #action_onehot[action] = 1\n",
    "            memory.push(state, action, next_state, reward) # Store the transition in memory\n",
    "            #next_state = torch.tensor(next_state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "            state = next_state\n",
    "            env.optimize_model() # perform one step of the optimization on the policy network\n",
    "\n",
    "            print(f\"net_worth: {env.net_worth}, step: {env.current_step}\")\n",
    "            if episode == train_episodes - 1:\n",
    "                env.save()\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "    \n",
    "def test_agent(env, visualize=True, test_episodes=1):\n",
    "    env.load() # load the model\n",
    "    for episode in range(test_episodes):\n",
    "        state = env.reset()\n",
    "        while True:\n",
    "            env.render(visualize)\n",
    "            action = env.act(state, mode='test')\n",
    "            state, reward, done = env.step(action)\n",
    "            print(f\"Episode {episode} net_worth:, {env.net_worth}\")\n",
    "            if env.current_step == env.end_step:\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lookback_window_size = 50\n",
    "data_path = \"./data/binance-BTCUSDT-1h.pkl\"\n",
    "df = pd.read_pickle(data_path)\n",
    "train_size = int(len(df) * 0.7)\n",
    "train_df = df[:train_size]\n",
    "test_df = df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>date_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_open</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-31 00:00:00</th>\n",
       "      <td>6394.45</td>\n",
       "      <td>6469.28</td>\n",
       "      <td>6380.00</td>\n",
       "      <td>6439.55</td>\n",
       "      <td>3456.744826</td>\n",
       "      <td>2020-03-31 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 01:00:00</th>\n",
       "      <td>6439.55</td>\n",
       "      <td>6515.00</td>\n",
       "      <td>6439.55</td>\n",
       "      <td>6514.07</td>\n",
       "      <td>2564.814102</td>\n",
       "      <td>2020-03-31 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 02:00:00</th>\n",
       "      <td>6514.78</td>\n",
       "      <td>6523.23</td>\n",
       "      <td>6445.00</td>\n",
       "      <td>6449.66</td>\n",
       "      <td>2638.245186</td>\n",
       "      <td>2020-03-31 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 03:00:00</th>\n",
       "      <td>6449.62</td>\n",
       "      <td>6480.00</td>\n",
       "      <td>6408.00</td>\n",
       "      <td>6439.47</td>\n",
       "      <td>3522.060908</td>\n",
       "      <td>2020-03-31 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 04:00:00</th>\n",
       "      <td>6439.47</td>\n",
       "      <td>6465.00</td>\n",
       "      <td>6378.00</td>\n",
       "      <td>6398.93</td>\n",
       "      <td>3855.135175</td>\n",
       "      <td>2020-03-31 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-20 19:00:00</th>\n",
       "      <td>27980.02</td>\n",
       "      <td>28013.00</td>\n",
       "      <td>27633.17</td>\n",
       "      <td>27785.10</td>\n",
       "      <td>16860.839580</td>\n",
       "      <td>2023-03-20 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-20 20:00:00</th>\n",
       "      <td>27784.57</td>\n",
       "      <td>28034.19</td>\n",
       "      <td>27752.94</td>\n",
       "      <td>28001.00</td>\n",
       "      <td>12624.378950</td>\n",
       "      <td>2023-03-20 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-20 21:00:00</th>\n",
       "      <td>28002.37</td>\n",
       "      <td>28186.71</td>\n",
       "      <td>27921.68</td>\n",
       "      <td>27996.09</td>\n",
       "      <td>11012.975200</td>\n",
       "      <td>2023-03-20 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-20 22:00:00</th>\n",
       "      <td>27996.09</td>\n",
       "      <td>28058.10</td>\n",
       "      <td>27859.75</td>\n",
       "      <td>27952.20</td>\n",
       "      <td>9715.082800</td>\n",
       "      <td>2023-03-20 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-20 23:00:00</th>\n",
       "      <td>27950.87</td>\n",
       "      <td>28015.21</td>\n",
       "      <td>27577.02</td>\n",
       "      <td>27717.01</td>\n",
       "      <td>14506.704940</td>\n",
       "      <td>2023-03-21 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26016 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close        volume  \\\n",
       "date_open                                                                   \n",
       "2020-03-31 00:00:00   6394.45   6469.28   6380.00   6439.55   3456.744826   \n",
       "2020-03-31 01:00:00   6439.55   6515.00   6439.55   6514.07   2564.814102   \n",
       "2020-03-31 02:00:00   6514.78   6523.23   6445.00   6449.66   2638.245186   \n",
       "2020-03-31 03:00:00   6449.62   6480.00   6408.00   6439.47   3522.060908   \n",
       "2020-03-31 04:00:00   6439.47   6465.00   6378.00   6398.93   3855.135175   \n",
       "...                       ...       ...       ...       ...           ...   \n",
       "2023-03-20 19:00:00  27980.02  28013.00  27633.17  27785.10  16860.839580   \n",
       "2023-03-20 20:00:00  27784.57  28034.19  27752.94  28001.00  12624.378950   \n",
       "2023-03-20 21:00:00  28002.37  28186.71  27921.68  27996.09  11012.975200   \n",
       "2023-03-20 22:00:00  27996.09  28058.10  27859.75  27952.20   9715.082800   \n",
       "2023-03-20 23:00:00  27950.87  28015.21  27577.02  27717.01  14506.704940   \n",
       "\n",
       "                             date_close  \n",
       "date_open                                \n",
       "2020-03-31 00:00:00 2020-03-31 01:00:00  \n",
       "2020-03-31 01:00:00 2020-03-31 02:00:00  \n",
       "2020-03-31 02:00:00 2020-03-31 03:00:00  \n",
       "2020-03-31 03:00:00 2020-03-31 04:00:00  \n",
       "2020-03-31 04:00:00 2020-03-31 05:00:00  \n",
       "...                                 ...  \n",
       "2023-03-20 19:00:00 2023-03-20 20:00:00  \n",
       "2023-03-20 20:00:00 2023-03-20 21:00:00  \n",
       "2023-03-20 21:00:00 2023-03-20 22:00:00  \n",
       "2023-03-20 22:00:00 2023-03-20 23:00:00  \n",
       "2023-03-20 23:00:00 2023-03-21 00:00:00  \n",
       "\n",
       "[26016 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>date_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_open</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-21 00:00:00</th>\n",
       "      <td>27717.01</td>\n",
       "      <td>27953.33</td>\n",
       "      <td>27664.51</td>\n",
       "      <td>27850.21</td>\n",
       "      <td>15105.73382</td>\n",
       "      <td>2023-03-21 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-21 01:00:00</th>\n",
       "      <td>27850.21</td>\n",
       "      <td>27934.63</td>\n",
       "      <td>27711.00</td>\n",
       "      <td>27875.65</td>\n",
       "      <td>13164.86421</td>\n",
       "      <td>2023-03-21 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-21 02:00:00</th>\n",
       "      <td>27874.60</td>\n",
       "      <td>27907.80</td>\n",
       "      <td>27773.29</td>\n",
       "      <td>27779.74</td>\n",
       "      <td>11442.54447</td>\n",
       "      <td>2023-03-21 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-21 03:00:00</th>\n",
       "      <td>27779.74</td>\n",
       "      <td>27838.00</td>\n",
       "      <td>27726.13</td>\n",
       "      <td>27787.29</td>\n",
       "      <td>11236.18652</td>\n",
       "      <td>2023-03-21 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-21 04:00:00</th>\n",
       "      <td>27787.29</td>\n",
       "      <td>27968.00</td>\n",
       "      <td>27780.05</td>\n",
       "      <td>27906.81</td>\n",
       "      <td>12637.07836</td>\n",
       "      <td>2023-03-21 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-27 11:00:00</th>\n",
       "      <td>61110.01</td>\n",
       "      <td>61314.20</td>\n",
       "      <td>61096.00</td>\n",
       "      <td>61196.02</td>\n",
       "      <td>580.05999</td>\n",
       "      <td>2024-06-27 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-27 12:00:00</th>\n",
       "      <td>61196.01</td>\n",
       "      <td>61660.00</td>\n",
       "      <td>61154.60</td>\n",
       "      <td>61341.88</td>\n",
       "      <td>1198.51794</td>\n",
       "      <td>2024-06-27 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-27 13:00:00</th>\n",
       "      <td>61341.87</td>\n",
       "      <td>61994.00</td>\n",
       "      <td>61314.00</td>\n",
       "      <td>61990.00</td>\n",
       "      <td>1761.82668</td>\n",
       "      <td>2024-06-27 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-27 14:00:00</th>\n",
       "      <td>61990.00</td>\n",
       "      <td>62389.22</td>\n",
       "      <td>61696.64</td>\n",
       "      <td>61729.99</td>\n",
       "      <td>2096.81938</td>\n",
       "      <td>2024-06-27 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-27 15:00:00</th>\n",
       "      <td>61730.00</td>\n",
       "      <td>61855.23</td>\n",
       "      <td>61532.45</td>\n",
       "      <td>61648.31</td>\n",
       "      <td>1002.98362</td>\n",
       "      <td>2024-06-27 16:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11151 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close       volume  \\\n",
       "date_open                                                                  \n",
       "2023-03-21 00:00:00  27717.01  27953.33  27664.51  27850.21  15105.73382   \n",
       "2023-03-21 01:00:00  27850.21  27934.63  27711.00  27875.65  13164.86421   \n",
       "2023-03-21 02:00:00  27874.60  27907.80  27773.29  27779.74  11442.54447   \n",
       "2023-03-21 03:00:00  27779.74  27838.00  27726.13  27787.29  11236.18652   \n",
       "2023-03-21 04:00:00  27787.29  27968.00  27780.05  27906.81  12637.07836   \n",
       "...                       ...       ...       ...       ...          ...   \n",
       "2024-06-27 11:00:00  61110.01  61314.20  61096.00  61196.02    580.05999   \n",
       "2024-06-27 12:00:00  61196.01  61660.00  61154.60  61341.88   1198.51794   \n",
       "2024-06-27 13:00:00  61341.87  61994.00  61314.00  61990.00   1761.82668   \n",
       "2024-06-27 14:00:00  61990.00  62389.22  61696.64  61729.99   2096.81938   \n",
       "2024-06-27 15:00:00  61730.00  61855.23  61532.45  61648.31   1002.98362   \n",
       "\n",
       "                             date_close  \n",
       "date_open                                \n",
       "2023-03-21 00:00:00 2023-03-21 01:00:00  \n",
       "2023-03-21 01:00:00 2023-03-21 02:00:00  \n",
       "2023-03-21 02:00:00 2023-03-21 03:00:00  \n",
       "2023-03-21 03:00:00 2023-03-21 04:00:00  \n",
       "2023-03-21 04:00:00 2023-03-21 05:00:00  \n",
       "...                                 ...  \n",
       "2024-06-27 11:00:00 2024-06-27 12:00:00  \n",
       "2024-06-27 12:00:00 2024-06-27 13:00:00  \n",
       "2024-06-27 13:00:00 2024-06-27 14:00:00  \n",
       "2024-06-27 14:00:00 2024-06-27 15:00:00  \n",
       "2024-06-27 15:00:00 2024-06-27 16:00:00  \n",
       "\n",
       "[11151 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26016"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11151"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = Actor(500).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.random.rand(50,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = actor(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.]], device='mps:0', grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = train_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6439.55    ,  6515.      ,  6439.55    ,  6514.07    ,\n",
       "         2564.814102,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6514.78    ,  6523.23    ,  6445.      ,  6449.66    ,\n",
       "         2638.245186,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6449.62    ,  6480.      ,  6408.      ,  6439.47    ,\n",
       "         3522.060908,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6439.47    ,  6465.      ,  6378.      ,  6398.93    ,\n",
       "         3855.135175,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6398.09    ,  6453.      ,  6380.96    ,  6415.6     ,\n",
       "         2207.248162,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6415.6     ,  6471.56    ,  6390.      ,  6471.56    ,\n",
       "         3093.525912,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6471.56    ,  6473.68    ,  6425.48    ,  6445.09    ,\n",
       "         2008.266984,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6445.11    ,  6505.5     ,  6441.71    ,  6493.93    ,\n",
       "         3412.169747,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6492.98    ,  6499.      ,  6425.      ,  6440.04    ,\n",
       "         3365.663583,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6440.04    ,  6441.3     ,  6404.      ,  6431.32    ,\n",
       "         2779.521484,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6431.48    ,  6432.29    ,  6330.01    ,  6387.19    ,\n",
       "         5307.474472,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6387.73    ,  6461.95    ,  6321.4     ,  6447.37    ,\n",
       "         4797.736674,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6447.23    ,  6481.28    ,  6400.07    ,  6418.      ,\n",
       "         4091.874182,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6418.      ,  6484.95    ,  6415.15    ,  6452.04    ,\n",
       "         3234.975701,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6452.04    ,  6500.      ,  6424.      ,  6454.12    ,\n",
       "         3921.332904,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6454.12    ,  6469.94    ,  6414.05    ,  6427.59    ,\n",
       "         2812.788888,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6427.48    ,  6459.      ,  6401.      ,  6452.79    ,\n",
       "         2362.325763,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6452.79    ,  6486.6     ,  6444.82    ,  6462.37    ,\n",
       "         2326.746275,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6462.87    ,  6475.      ,  6430.32    ,  6463.47    ,\n",
       "         2485.858941,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6465.32    ,  6494.9     ,  6447.75    ,  6467.5     ,\n",
       "         2503.512996,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6467.34    ,  6485.      ,  6420.      ,  6442.61    ,\n",
       "         2112.043684,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6442.6     ,  6448.      ,  6420.64    ,  6431.55    ,\n",
       "         1197.645169,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6431.55    ,  6440.99    ,  6386.89    ,  6410.44    ,\n",
       "         2279.883541,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6412.14    ,  6426.52    ,  6239.34    ,  6305.12    ,\n",
       "         9061.280945,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6305.5     ,  6327.93    ,  6285.25    ,  6293.64    ,\n",
       "         2275.174783,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6291.99    ,  6320.49    ,  6287.6     ,  6317.4     ,\n",
       "         1805.203416,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6318.24    ,  6381.7     ,  6310.89    ,  6368.68    ,\n",
       "         2948.571424,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6368.74    ,  6376.28    ,  6333.06    ,  6342.      ,\n",
       "         1834.461796,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6342.01    ,  6346.99    ,  6288.23    ,  6304.46    ,\n",
       "         2019.881293,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6304.46    ,  6322.      ,  6271.14    ,  6299.79    ,\n",
       "         3532.852801,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6299.77    ,  6337.96    ,  6287.03    ,  6331.96    ,\n",
       "         2211.291462,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6330.87    ,  6330.87    ,  6285.      ,  6306.69    ,\n",
       "         2200.56454 ,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6307.01    ,  6314.3     ,  6257.32    ,  6300.      ,\n",
       "         2730.942571,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6299.99    ,  6320.1     ,  6286.58    ,  6291.71    ,\n",
       "         2061.051311,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6291.      ,  6306.09    ,  6269.99    ,  6296.87    ,\n",
       "         2152.682932,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6297.      ,  6340.81    ,  6210.93    ,  6219.29    ,\n",
       "         6114.421833,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6219.29    ,  6239.89    ,  6170.      ,  6206.39    ,\n",
       "         4265.084035,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6205.99    ,  6260.73    ,  6199.      ,  6251.13    ,\n",
       "         3685.062345,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6250.51    ,  6258.43    ,  6215.01    ,  6230.09    ,\n",
       "         2774.812535,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6230.01    ,  6230.01    ,  6150.11    ,  6182.38    ,\n",
       "         4617.679879,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6182.38    ,  6212.      ,  6165.07    ,  6194.57    ,\n",
       "         2414.859342,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6194.56    ,  6220.      ,  6184.32    ,  6186.86    ,\n",
       "         1801.090689,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6187.99    ,  6212.96    ,  6164.28    ,  6200.81    ,\n",
       "         2408.938106,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6200.11    ,  6380.      ,  6193.1     ,  6337.      ,\n",
       "         6818.827306,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6337.45    ,  6400.      ,  6332.6     ,  6354.      ,\n",
       "         4350.744084,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6354.      ,  6594.97    ,  6352.52    ,  6520.75    ,\n",
       "        12176.841884,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6520.76    ,  6679.94    ,  6500.      ,  6642.92    ,\n",
       "        11238.431088,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6643.36    ,  6744.      ,  6580.      ,  6617.76    ,\n",
       "         9703.860411,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6617.24    ,  6639.23    ,  6551.      ,  6566.08    ,\n",
       "         4225.665454,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ],\n",
       "       [ 6567.37    ,  6617.48    ,  6563.96    ,  6604.93    ,\n",
       "         2907.396035,  1000.      ,  1000.      ,     0.      ,\n",
       "            0.      ,     0.      ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([[6439.55, 6515.0, 6439.55, 6514.07, 2564.814102],\n",
       "       [6514.78, 6523.23, 6445.0, 6449.66, 2638.245186],\n",
       "       [6449.62, 6480.0, 6408.0, 6439.47, 3522.060908],\n",
       "       [6439.47, 6465.0, 6378.0, 6398.93, 3855.135175],\n",
       "       [6398.09, 6453.0, 6380.96, 6415.6, 2207.248162],\n",
       "       [6415.6, 6471.56, 6390.0, 6471.56, 3093.525912],\n",
       "       [6471.56, 6473.68, 6425.48, 6445.09, 2008.266984],\n",
       "       [6445.11, 6505.5, 6441.71, 6493.93, 3412.169747],\n",
       "       [6492.98, 6499.0, 6425.0, 6440.04, 3365.663583],\n",
       "       [6440.04, 6441.3, 6404.0, 6431.32, 2779.521484],\n",
       "       [6431.48, 6432.29, 6330.01, 6387.19, 5307.474472],\n",
       "       [6387.73, 6461.95, 6321.4, 6447.37, 4797.736674],\n",
       "       [6447.23, 6481.28, 6400.07, 6418.0, 4091.874182],\n",
       "       [6418.0, 6484.95, 6415.15, 6452.04, 3234.975701],\n",
       "       [6452.04, 6500.0, 6424.0, 6454.12, 3921.332904],\n",
       "       [6454.12, 6469.94, 6414.05, 6427.59, 2812.788888],\n",
       "       [6427.48, 6459.0, 6401.0, 6452.79, 2362.325763],\n",
       "       [6452.79, 6486.6, 6444.82, 6462.37, 2326.746275],\n",
       "       [6462.87, 6475.0, 6430.32, 6463.47, 2485.858941],\n",
       "       [6465.32, 6494.9, 6447.75, 6467.5, 2503.512996],\n",
       "       [6467.34, 6485.0, 6420.0, 6442.61, 2112.043684],\n",
       "       [6442.6, 6448.0, 6420.64, 6431.55, 1197.645169],\n",
       "       [6431.55, 6440.99, 6386.89, 6410.44, 2279.883541],\n",
       "       [6412.14, 6426.52, 6239.34, 6305.12, 9061.280945],\n",
       "       [6305.5, 6327.93, 6285.25, 6293.64, 2275.174783],\n",
       "       [6291.99, 6320.49, 6287.6, 6317.4, 1805.203416],\n",
       "       [6318.24, 6381.7, 6310.89, 6368.68, 2948.571424],\n",
       "       [6368.74, 6376.28, 6333.06, 6342.0, 1834.461796],\n",
       "       [6342.01, 6346.99, 6288.23, 6304.46, 2019.881293],\n",
       "       [6304.46, 6322.0, 6271.14, 6299.79, 3532.852801],\n",
       "       [6299.77, 6337.96, 6287.03, 6331.96, 2211.291462],\n",
       "       [6330.87, 6330.87, 6285.0, 6306.69, 2200.56454],\n",
       "       [6307.01, 6314.3, 6257.32, 6300.0, 2730.942571],\n",
       "       [6299.99, 6320.1, 6286.58, 6291.71, 2061.051311],\n",
       "       [6291.0, 6306.09, 6269.99, 6296.87, 2152.682932],\n",
       "       [6297.0, 6340.81, 6210.93, 6219.29, 6114.421833],\n",
       "       [6219.29, 6239.89, 6170.0, 6206.39, 4265.084035],\n",
       "       [6205.99, 6260.73, 6199.0, 6251.13, 3685.062345],\n",
       "       [6250.51, 6258.43, 6215.01, 6230.09, 2774.812535],\n",
       "       [6230.01, 6230.01, 6150.11, 6182.38, 4617.679879],\n",
       "       [6182.38, 6212.0, 6165.07, 6194.57, 2414.859342],\n",
       "       [6194.56, 6220.0, 6184.32, 6186.86, 1801.090689],\n",
       "       [6187.99, 6212.96, 6164.28, 6200.81, 2408.938106],\n",
       "       [6200.11, 6380.0, 6193.1, 6337.0, 6818.827306],\n",
       "       [6337.45, 6400.0, 6332.6, 6354.0, 4350.744084],\n",
       "       [6354.0, 6594.97, 6352.52, 6520.75, 12176.841884],\n",
       "       [6520.76, 6679.94, 6500.0, 6642.92, 11238.431088],\n",
       "       [6643.36, 6744.0, 6580.0, 6617.76, 9703.860411],\n",
       "       [6617.24, 6639.23, 6551.0, 6566.08, 4225.665454],\n",
       "       [6567.37, 6617.48, 6563.96, 6604.93, 2907.396035]],\n",
       "      maxlen=50)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env.market_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([[1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0]],\n",
       "      maxlen=50)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env.orders_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = train_env.act(obs, testmode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0299]], dtype=torch.float64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([[6439.55, 6515.0, 6439.55, 6514.07, 2564.814102],\n",
       "       [6514.78, 6523.23, 6445.0, 6449.66, 2638.245186],\n",
       "       [6449.62, 6480.0, 6408.0, 6439.47, 3522.060908],\n",
       "       [6439.47, 6465.0, 6378.0, 6398.93, 3855.135175],\n",
       "       [6398.09, 6453.0, 6380.96, 6415.6, 2207.248162],\n",
       "       [6415.6, 6471.56, 6390.0, 6471.56, 3093.525912],\n",
       "       [6471.56, 6473.68, 6425.48, 6445.09, 2008.266984],\n",
       "       [6445.11, 6505.5, 6441.71, 6493.93, 3412.169747],\n",
       "       [6492.98, 6499.0, 6425.0, 6440.04, 3365.663583],\n",
       "       [6440.04, 6441.3, 6404.0, 6431.32, 2779.521484],\n",
       "       [6431.48, 6432.29, 6330.01, 6387.19, 5307.474472],\n",
       "       [6387.73, 6461.95, 6321.4, 6447.37, 4797.736674],\n",
       "       [6447.23, 6481.28, 6400.07, 6418.0, 4091.874182],\n",
       "       [6418.0, 6484.95, 6415.15, 6452.04, 3234.975701],\n",
       "       [6452.04, 6500.0, 6424.0, 6454.12, 3921.332904],\n",
       "       [6454.12, 6469.94, 6414.05, 6427.59, 2812.788888],\n",
       "       [6427.48, 6459.0, 6401.0, 6452.79, 2362.325763],\n",
       "       [6452.79, 6486.6, 6444.82, 6462.37, 2326.746275],\n",
       "       [6462.87, 6475.0, 6430.32, 6463.47, 2485.858941],\n",
       "       [6465.32, 6494.9, 6447.75, 6467.5, 2503.512996],\n",
       "       [6467.34, 6485.0, 6420.0, 6442.61, 2112.043684],\n",
       "       [6442.6, 6448.0, 6420.64, 6431.55, 1197.645169],\n",
       "       [6431.55, 6440.99, 6386.89, 6410.44, 2279.883541],\n",
       "       [6412.14, 6426.52, 6239.34, 6305.12, 9061.280945],\n",
       "       [6305.5, 6327.93, 6285.25, 6293.64, 2275.174783],\n",
       "       [6291.99, 6320.49, 6287.6, 6317.4, 1805.203416],\n",
       "       [6318.24, 6381.7, 6310.89, 6368.68, 2948.571424],\n",
       "       [6368.74, 6376.28, 6333.06, 6342.0, 1834.461796],\n",
       "       [6342.01, 6346.99, 6288.23, 6304.46, 2019.881293],\n",
       "       [6304.46, 6322.0, 6271.14, 6299.79, 3532.852801],\n",
       "       [6299.77, 6337.96, 6287.03, 6331.96, 2211.291462],\n",
       "       [6330.87, 6330.87, 6285.0, 6306.69, 2200.56454],\n",
       "       [6307.01, 6314.3, 6257.32, 6300.0, 2730.942571],\n",
       "       [6299.99, 6320.1, 6286.58, 6291.71, 2061.051311],\n",
       "       [6291.0, 6306.09, 6269.99, 6296.87, 2152.682932],\n",
       "       [6297.0, 6340.81, 6210.93, 6219.29, 6114.421833],\n",
       "       [6219.29, 6239.89, 6170.0, 6206.39, 4265.084035],\n",
       "       [6205.99, 6260.73, 6199.0, 6251.13, 3685.062345],\n",
       "       [6250.51, 6258.43, 6215.01, 6230.09, 2774.812535],\n",
       "       [6230.01, 6230.01, 6150.11, 6182.38, 4617.679879],\n",
       "       [6182.38, 6212.0, 6165.07, 6194.57, 2414.859342],\n",
       "       [6194.56, 6220.0, 6184.32, 6186.86, 1801.090689],\n",
       "       [6187.99, 6212.96, 6164.28, 6200.81, 2408.938106],\n",
       "       [6200.11, 6380.0, 6193.1, 6337.0, 6818.827306],\n",
       "       [6337.45, 6400.0, 6332.6, 6354.0, 4350.744084],\n",
       "       [6354.0, 6594.97, 6352.52, 6520.75, 12176.841884],\n",
       "       [6520.76, 6679.94, 6500.0, 6642.92, 11238.431088],\n",
       "       [6643.36, 6744.0, 6580.0, 6617.76, 9703.860411],\n",
       "       [6617.24, 6639.23, 6551.0, 6566.08, 4225.665454],\n",
       "       [6567.37, 6617.48, 6563.96, 6604.93, 2907.396035]],\n",
       "      maxlen=50)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env.market_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([[1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [1000, 1000, 0, 0, 0],\n",
       "       [tensor([[970.1267]], dtype=torch.float64),\n",
       "        tensor([[1000.]], dtype=torch.float64),\n",
       "        tensor([[0.0045]], dtype=torch.float64),\n",
       "        0,\n",
       "        tensor([[0.0045]], dtype=torch.float64)]],\n",
       "      maxlen=50)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env.orders_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (50, 5) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m obs, reward, done \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 138\u001b[0m, in \u001b[0;36mTradingEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m#obs = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs, reward, done\n",
      "Cell \u001b[0;32mIn[48], line 87\u001b[0m, in \u001b[0;36mTradingEnv._next_observation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_observation\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarket_history\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     82\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     83\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     84\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     85\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     86\u001b[0m                                 ])\n\u001b[0;32m---> 87\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarket_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morders_history\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m#obs = np.concatenate((np.array(self.market_history), np.array(self.orders_history.cpu())), axis=1)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m#obs =torch.cat([self.market_history, self.orders_history], dim=0)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obs\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (50, 5) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "obs, reward, done = train_env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m obs, reward, done \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 138\u001b[0m, in \u001b[0;36mTradingEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m#obs = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs, reward, done\n",
      "Cell \u001b[0;32mIn[6], line 87\u001b[0m, in \u001b[0;36mTradingEnv._next_observation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_observation\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarket_history\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     82\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     83\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     84\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     85\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     86\u001b[0m                                 ])\n\u001b[0;32m---> 87\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarket_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morders_history\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m#obs = np.concatenate((np.array(self.market_history), np.array(self.orders_history.cpu())), axis=1)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m#obs =torch.cat([self.market_history, self.orders_history], dim=0)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obs\n",
      "File \u001b[0;32m~/Desktop/MATH70101 Deep Learning/Coursework III/dl-cw-3-gpu/lib/python3.11/site-packages/torch/_tensor.py:1083\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "obs, reward, done = train_env.step(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(221)\n",
    "\n",
    "# equivalent but more general\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "\n",
    "# add a subplot with no frame\n",
    "ax2 = plt.subplot(1,3,2)\n",
    "\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "\n",
    "# add a polar subplot\n",
    "plt.subplot(223, projection='polar')\n",
    "\n",
    "# add a red subplot that shares the x-axis with ax1\n",
    "plt.subplot(224, sharex=ax1, facecolor='red')\n",
    "\n",
    "# delete ax2 from the figure\n",
    "plt.delaxes(ax2)\n",
    "\n",
    "# add ax2 to the figure again\n",
    "plt.subplot(ax2)\n",
    "\n",
    "# make the first Axes \"current\" again\n",
    "plt.subplot(221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "testarr = np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtestarr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "testarr[1] += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(-1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.5000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.clamp(a, -1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "a = torch.tensor(-1.5)\n",
    "m = Normal(-1, 1.0)\n",
    "#z = torch.atanh(torch.clamp(a, -1.0, 1.0))\n",
    "log_prob_old = m.log_prob(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal(loc: -1.0, scale: 1.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = torch.tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "memory = deque([], maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [[0, 1], [1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-cw-3-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
